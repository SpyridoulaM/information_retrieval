{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "3623a07f-b6b9-4926-8553-3e93d7a2c6f0",
      "cell_type": "markdown",
      "source": "Βήμα 1. Συλλογή δεδομένων:",
      "metadata": {}
    },
    {
      "id": "bd448e6c-ad46-4bf6-9057-e93defa71cab",
      "cell_type": "markdown",
      "source": "Η συλλογή των δεδομένων έγινε από το kaggle στην διεύθυνση https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots/data και η συλλογή περιέχει στοιχεία και υποθέσεις ταινιών.\nΚατεβάζουμε τις απαραίτητες βιβλιοθήκες και περιορίζουμε το μέγεθος του dataset στις πρώτες 1000 εγγραφές λόγω περιορισμένων υπολογιστικών πόρων.",
      "metadata": {}
    },
    {
      "id": "7dd3b56b-dbfa-4f85-85ff-970a52d94aa9",
      "cell_type": "code",
      "source": "import pandas as pd\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom collections import defaultdict\nimport json\nimport string\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score\nfrom rank_bm25 import BM25Okapi\n\nnltk.download('stopwords')\nnltk.download('punkt')\n\n# Φόρτωση των δεδομένων\ndata = pd.read_csv('wiki_movie_plots_deduped.csv')\ndata = data.head(1000)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "98e77faa-3486-48fa-b94f-9fb06be9016a",
      "cell_type": "markdown",
      "source": "Βήμα 2. Προεπεξεργασία κειμένου (Text Processing):\nΓίνεται διαγραφή των εγγραφών των οποίων είναι άδειο το plot, αφαιρούνται τα stopwords και εφαρμόζεται επεξεργασία stemming.",
      "metadata": {}
    },
    {
      "id": "09e7eb00-afc8-4831-becb-00448498c387",
      "cell_type": "code",
      "source": "stemmer = PorterStemmer()\n\n# Διαγραφή των εγγραφων οι οποίες έχουν άδειο το κομμάτι plot\ndata = data.dropna(subset=['Plot'])\n\n# Αποθήκευση του καθαρισμένου αρχείου\ndata.to_csv('cleaned_movies_dataset.csv', index=False)\n\n# Καθορισμός των stopwords\nstopwords = nltk.corpus.stopwords.words(\"english\")\n\n# Λειτουργία προετοιμασίας κειμένου με Stemming\ndef preprocess_text_with_stemming(text):\n    # Αφαίρεση ειδικών χαρακτήρων\n    text = ''.join([char for char in text if char not in string.punctuation])\n    # Μετατροπή σε μικρά και tokenization\n    text = text.lower()\n    tokens = nltk.word_tokenize(text)\n    # Αφαίρεση stopwords\n    tokens = [token for token in tokens if token not in stopwords]\n    # Stemming\n    tokens = [stemmer.stem(token) for token in tokens]\n    # Αφαίρεση πολλαπλών κενών\n    text = \" \".join(tokens)\n    return text\n\ndata['Processed_Plot'] = data['Plot'].apply(preprocess_text_with_stemming)\n\n# Αποθήκευση του καθαρισμένου dataset\ndata.to_csv('preprocessed_movies_dataset_with_stemming.csv', index=False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dcf735c1-bc29-4a4d-8205-dc73e9a0cc1b",
      "cell_type": "markdown",
      "source": "Βήμα 3. Ευρετήριο (Indexing):\nΧρησιμοποιούμε το inverted index για να συνδέσουμε τις λέξεις με τα έγγραφα στα οποία εμφανίζονται",
      "metadata": {}
    },
    {
      "id": "62025d0d-4d8f-4124-a145-8d1865fd2577",
      "cell_type": "code",
      "source": "# Δημιουργία δομής ανεστραμμένου ευρετηρίου\ninverted_index = defaultdict(list)\n\n# Κατασκευή του ευρετηρίου\nfor idx, row in data.iterrows(): \n    doc_id = idx # Το ID του εγγράφου (μπορεί να είναι η γραμμή)\n    words = row['Processed_Plot'].split() # Διάσπαση κειμένου σε λέξεις\n    for word in words:\n        if doc_id not in inverted_index[word]: # Αποφυγή διπλών εγγραφών\n            inverted_index[word].append(doc_id)\n\n# Εγγραφή του ευρετηρίου σε αρχείο\nwith open('inverted_index.json', 'w') as f:\n    json.dump(inverted_index, f)\n# Φόρτωση του ευρετηρίου σε αρχείο\nwith open('inverted_index.json', 'r') as f:\n    inverted_index = json.load(f)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b8b53058-e442-478f-b487-b9844e31032e",
      "cell_type": "markdown",
      "source": "Βήμα 4. Μηχανή αναζήτησης (Search Engine)",
      "metadata": {}
    },
    {
      "id": "ceb7cdc6-1685-4822-9214-9d4a100e6b12",
      "cell_type": "markdown",
      "source": "α) Επεξεργασία ερωτήματος (Query Processing):\nΗ συνάρτηση boolean_search επεξεργάζεται τις λέξεις μέσω stemming,\nτο οποίο σημαίνει ότι κάθε λέξη μετατρέπεται στην ρίζα της (lemma) για να \nμειωθεί η πολυπλοκότητα της γλώσσας και να βελτιωθεί η αναζήτηση. Στη συνέχεια, \nαναγνωρίζει και εφαρμόζει λογικούς τελεστές Boolean όπως AND, OR και NOT για να εντοπίσει \nτα σχετικά έγγραφα στον αναστραμμένο ευρετήριο (inverted index). Το αποτέλεσμα είναι \nτο σύνολο των εγγράφων που ικανοποιούν το ερώτημα αναζήτησης.",
      "metadata": {}
    },
    {
      "id": "45cd1d4e-2639-455c-8a4a-2e238b5d5ffc",
      "cell_type": "code",
      "source": "def boolean_search(query, inverted_index):\n    # Καθαρισμός και tokenization του ερωτήματος\n    query = query.lower() # Μετατροπή σε μικρά γράμματα\n    tokens = word_tokenize(query) # Tokenization\n    tokens = [token for token in tokens if token not in stopwords]\n    # Stemming σε κάθε λέξη\n    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n    \n    result_set = set()\n    # Αναζήτηση για AND, OR, NOT\n    if \"and\" in stemmed_tokens:\n        terms = [term for term in stemmed_tokens if term != \"and\"]\n        result_set = set(inverted_index.get(terms[0], []))\n        for term in terms[1:]:\n            result_set &= set(inverted_index.get(term, []))\n    elif \"or\" in stemmed_tokens:\n        terms = [term for term in stemmed_tokens if term != \"or\"]\n        for term in terms:\n            result_set |= set(inverted_index.get(term, []))\n    elif \"not\" in stemmed_tokens:\n        terms = [term for term in stemmed_tokens if term != \"not\"]\n        result_set = set(inverted_index.keys()) - set(inverted_index.get(terms[0], []))\n    else:\n        result_set = set(inverted_index.get(stemmed_tokens[0], [])) # Απλή αναζήτηση\n\n    return result_set",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a829014c-588f-4382-809b-c7cdb0a6f82b",
      "cell_type": "markdown",
      "source": "β) Κατάταξη αποτελεσμάτων (Ranking):",
      "metadata": {}
    },
    {
      "id": "f325f165-c98a-4314-a23d-27488c2bb270",
      "cell_type": "markdown",
      "source": "Οι μέθοδοι αναζήτησης TF-IDF και BM25 κατατάσουν τα έγγραφα με βάση την συνάφεια. \nΣυγκεκριμένα υπολογίζουν τη σημασία μιας λέξης σε ένα έγγραφο, βασισμένη στη \nσυχνότητά της στο έγγραφο και τη σπανιότητά της σε όλο το σύνολο εγγράφων.\n\nΤο BM25 επηρεάζεται από το μήκος του εγγράφου και μειώνεται η επίδραση συχνών λέξεων, \nενώ το TF-IDF βασίζεται στη συχνότητα λέξεων και την αντίστροφη συχνότητα τους.",
      "metadata": {}
    },
    {
      "id": "3902fc15-1ac1-4775-99ba-50f06b6633b8",
      "cell_type": "code",
      "source": "# TF-IDF Search\ndef tfidf_search(query, data):\n    # Ένωση του dataset με το ερώτημα\n    documents = data['Processed_Plot'].tolist()\n    documents.append(preprocess_text_with_stemming(query))\n\n    # Υπολογισμός των TF-IDF διανυσμάτων\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform(documents)\n\n    # Υπολογισμός του cosine similarity\n    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n\n    # Ταξινόμηση των εγγράφων βάσει ομοιότητας\n    related_docs_indices = cosine_similarities.argsort()[::-1]\n\n    # Επιστροφή των δεικτών των εγγράφων και της ομοιότητας του καθενός\n    return [(index, cosine_similarities[index]) for index in related_docs_indices if cosine_similarities[index] > 0]\n\ntokenized_corpus = [doc.split() for doc in data['Processed_Plot']]\nbm25 = BM25Okapi(tokenized_corpus)\n\ndef bm25_search(query, data):\n    #Tokenization\n    query_tokens = word_tokenize(query.lower())\n    #Stemming και φιλτράρισμα για stop words\n    query_stemmed = [stemmer.stem(token) for token in query_tokens if token not in stopwords]\n    #Υπολογισμός BM25 βαθμολογίας\n    scores = bm25.get_scores(query_stemmed)\n    #Ταξινόμηση των εγγράφων βάσει της βαθμολογίας\n    ranked_results = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n    return [(idx, score) for idx, score in ranked_results if score > 0]\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1bf38eec-2fc9-403b-ab9b-ccb968d63500",
      "cell_type": "markdown",
      "source": "Βήμα 5. Αξιολόγηση συστήματος:",
      "metadata": {}
    },
    {
      "id": "9a2dce54-cbfe-4142-b9d6-6b5f78b11e1b",
      "cell_type": "code",
      "source": "def load_qry_file(filepath):\n    queries = {}\n    with open(filepath, 'r') as file:\n        lines = file.readlines()\n        current_query_id = None\n        current_query_text = \"\"\n        for line in lines:\n            if line.startswith(\".I\"):\n                if current_query_id is not None:\n                    queries[current_query_id] = current_query_text.strip()\n                current_query_id = int(line.split()[1])\n                current_query_text = \"\"\n            elif line.startswith(\".W\"):\n                continue\n            else:\n                current_query_text += line.strip() + \" \"\n        if current_query_id is not None:\n            queries[current_query_id] = current_query_text.strip()\n    # Έλεγχος αν το queries είναι άδειο\n    if not queries:\n        print(\"Σφάλμα: Το αρχείο ερωτημάτων είναι κενό ή δεν φορτώθηκε σωστά.\")\n    else:\n        print(f\"Φόρτωση ολοκληρώθηκε: {len(queries)} ερωτήματα.\")\n    return queries\n\ndef load_rel_file(filepath):\n    relevance_info = {}\n    with open(filepath, 'r') as file:\n        lines = file.readlines()\n        for line in lines:\n            parts = line.strip().split()\n            if len(parts) >= 2:\n                query_id = int(parts[0])\n                doc_id = int(parts[1])\n                if query_id not in relevance_info:\n                    relevance_info[query_id] = []\n                relevance_info[query_id].append(doc_id)\n    # Έλεγχος αν το relevance_info είναι άδειο\n    if not relevance_info:\n        print(\"Σφάλμα: Το αρχείο σχετικών εγγράφων είναι κενό ή δεν φορτώθηκε σωστά.\")\n    else:\n        print(f\"Φόρτωση ολοκληρώθηκε: {len(relevance_info)} ερωτήματα με σχετικές εγγραφές.\")\n    return relevance_info\n\ndef load_doc_file(file_path):\n    documents = {}\n    with open(file_path, 'r') as file:\n        content = file.read().strip().split(\".I\")\n        for item in content[1:]:\n            lines = item.strip().split(\"\\n\")\n            try:\n                doc_id = int(lines[0].strip())  \n            except ValueError:\n                continue\n            doc_text = \" \".join(line.strip() for line in lines[1:])\n            documents[doc_id] = doc_text\n    return documents\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "10325a00-84c7-452b-b520-8276a00ee6e7",
      "cell_type": "code",
      "source": "def create_inverted_index(data):\n    inverted_index = defaultdict(list)\n    for idx, row in data.iterrows(): \n        words = row['Processed_Plot'].split()\n        for word in words:\n            if idx not in inverted_index[word]:\n                inverted_index[word].append(idx)\n    return inverted_index",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2d43cb5c-a773-421d-992a-c7dd4c1868f7",
      "cell_type": "code",
      "source": "def user_choice():\n    print(\"Επιλέξτε μια επιλογή:\")\n    print(\"1: Αναζήτηση\")\n    print(\"2: Δοκιμή και υπολογισμός ακρίβειας, ανάκλησης, F1-score και MAP\")\n    choice = input(\"Επιλέξτε 1 ή 2: \")\n\n    if choice == '1':\n        print(\"Μηχανή Αναζήτησης (CLI)\")\n        search_method = input(\"Επιλέξτε μέθοδο αναζήτησης ('boolean', 'tfidf', 'bm25'): \").strip().lower()\n        \n        while True:\n            query = input(\"Δώστε το ερώτημα (ή 'exit' για έξοδο): \")\n            if query.lower() == \"exit\":\n                print(\"Έξοδος από τη μηχανή αναζήτησης.\")\n                break\n\n            if search_method == 'boolean': \n                results = boolean_search(query, inverted_index)\n                print(f\"Βρέθηκαν {len(results)} σχετικά έγγραφα:\")\n                for idx in results:\n                    title = data.loc[idx, 'Title']\n                    release_year = data.loc[idx, 'Release Year']\n                    print(f\"Έγγραφο ID: {idx}, Τίτλος: {title}, Έτος: {release_year}\\n\")\n            elif search_method == 'tfidf':\n                results = tfidf_search(query, data)\n                print(f\"Βρέθηκαν {len(results)} σχετικά έγγραφα:\")\n                for idx, score in results:\n                    title = data.loc[idx, 'Title']\n                    release_year = data.loc[idx, 'Release Year']\n                    print(f\"Έγγραφο ID: {idx}, Τίτλος: {title}, Έτος: {release_year}, Βαθμολογία TF-IDF: {score:.4f}\\n\")\n            elif search_method == 'bm25':\n                results = bm25_search(query, data)\n                print(f\"Βρέθηκαν {len(results)} σχετικά έγγραφα:\")\n                for idx, score in results:\n                    title = data.loc[idx, 'Title']\n                    release_year = data.loc[idx, 'Release Year']\n                    print(f\"Έγγραφο ID: {idx}, Τίτλος: {title}, Έτος: {release_year}, Βαθμολογία BM25: {score:.4f}\\n\")\n            else:\n                print(\"Μη έγκυρη μέθοδος αναζήτησης. Παρακαλώ επιλέξτε 'boolean', 'tfidf', 'bm25'\")\n                break\n            \n    elif choice == '2':\n        queries = load_qry_file('CISI.QRY')\n        relevance_info = load_rel_file('CISI.REL')\n        def evaluate_search_results(query_id, retrieved_docs, relevance_info):\n            relevant_docs = set(relevance_info.get(query_id, []))\n            retrieved_docs = set(retrieved_docs)\n            \n            # Ελέγξτε αν υπάρχουν σχετικά έγγραφα για το τρέχον ερώτημα\n            if not relevant_docs:\n                return 0.0, 0.0, 0.0, 0.0  # Επιστροφή μηδενικών τιμών αν δεν υπάρχουν σχετικά έγγραφα\n        \n            # Υπολογισμός Ακρίβειας, Ανάκλησης και F1 μόνο αν υπάρχουν ανακτηθέντα έγγραφα\n            if not retrieved_docs:\n                return 0.0, 0.0, 0.0, 0.0  # Επιστροφή μηδενικών τιμών αν δεν υπάρχουν ανακτηθέντα έγγραφα\n        \n            y_true = [1 if doc_id in relevant_docs else 0 for doc_id in retrieved_docs]\n            y_pred = [1] * len(retrieved_docs)  # Όλα τα ανακτηθέντα έγγραφα προβλέπονται ως σχετικά\n            \n            # Υπολογισμός Ακρίβειας, Ανάκλησης και F1 μόνο αν υπάρχουν σχετικά έγγραφα\n            precision = precision_score(y_true, y_pred, zero_division=0) if any(y_true) else 0.0\n            recall = recall_score(y_true, y_pred, zero_division=0) if any(y_true) else 0.0\n            f1 = f1_score(y_true, y_pred, zero_division=0) if any(y_true) else 0.0\n            \n            # Υπολογισμός Μέσης Ακρίβειας (AP) μόνο αν υπάρχουν ανακτηθέντα έγγραφα\n            ap = average_precision_score(y_true, [1] * len(retrieved_docs)) if any(y_true) else 0.0\n        \n            return precision, recall, f1, ap\n\n        def evaluate_all_queries(queries, relevance_info, data, search_method):\n            total_precision = 0\n            total_recall = 0\n            total_f1 = 0\n            total_ap = 0\n            num_queries = len(queries)\n\n            for query_id, query_text in queries.items():\n                if search_method == 'boolean':\n                    inverted_index = create_inverted_index(data)\n                    retrieved_docs = list(boolean_search(query_text, inverted_index))\n                elif search_method == 'tfidf':\n                    retrieved_docs = [idx for idx, _ in tfidf_search(query_text, data)]\n                elif search_method == 'bm25':\n                    retrieved_docs = [idx for idx, _ in bm25_search(query_text, data)]\n                else:\n                    print(\"Μη έγκυρη μέθοδος αναζήτησης.\")\n                    continue\n\n                precision, recall, f1, ap = evaluate_search_results(query_id, retrieved_docs, relevance_info)\n\n                total_precision += precision\n                total_recall += recall\n                total_f1 += f1\n                total_ap += ap\n\n            # Υπολογισμός και εκτύπωση των συνολικών αποτελεσμάτων\n            mean_precision = total_precision / num_queries\n            mean_recall = total_recall / num_queries\n            mean_f1 = total_f1 / num_queries\n            mean_ap = total_ap / num_queries\n\n            print(f\"\\nΣυνολική Αξιολόγηση {search_method}:\")\n            print(f\"Μέση Ακρίβεια: {mean_precision:.4f}\")\n            print(f\"Μέση Ανάκληση: {mean_recall:.4f}\")\n            print(f\"Μέσος Όρος F1-Score: {mean_f1:.4f}\")\n            print(f\"Μέση Ακρίβεια (MAP): {mean_ap:.4f}\")\n\n        search_method = \"boolean\"\n        evaluate_all_queries(queries, relevance_info, data, search_method)\n        search_method = \"tfidf\"\n        evaluate_all_queries(queries, relevance_info, data, search_method)\n        search_method = \"bm25\"\n        evaluate_all_queries(queries, relevance_info, data, search_method)\n        \n    else:\n        print(\"Ακατάλληλη επιλογή, προσπαθήστε ξανά.\")\n        user_choice()\n\nuser_choice()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}